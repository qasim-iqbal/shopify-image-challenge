{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import kerastuner as kt\n",
    "\n",
    "import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "\n",
    "import tensorflow.keras.losses as losses\n",
    "import tensorflow.keras.metrics as metrics\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"..\\clothing-dataset\\images.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_categories = dataset.groupby('label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb_categories.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>sender_id</th>\n",
       "      <th>kids</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dress</th>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longsleeve</th>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not sure</th>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outwear</th>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pants</th>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shirt</th>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoes</th>\n",
       "      <td>431</td>\n",
       "      <td>431</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shorts</th>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-Shirt</th>\n",
       "      <td>1011</td>\n",
       "      <td>1011</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            image  sender_id  kids\n",
       "label                             \n",
       "Dress         357        357   357\n",
       "Longsleeve    699        699   699\n",
       "Not sure      228        228   228\n",
       "Outwear       312        312   312\n",
       "Pants         692        692   692\n",
       "Shirt         378        378   378\n",
       "Shoes         431        431   431\n",
       "Shorts        308        308   308\n",
       "T-Shirt      1011       1011  1011"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_categories[gb_categories['image'] > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {'T-Shirt':0, 'Pants':1, 'Longsleeve':2, 'Dress':3, 'Shoes':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.query(f\"label in {[*dict_labels]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = dataset[['image','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qasim\\AppData\\Local\\Temp/ipykernel_2068/445683494.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_main['y'] = df_main['label'].replace(dict_labels)\n"
     ]
    }
   ],
   "source": [
    "df_main['y'] = df_main['label'].replace(dict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['img_path'] = df_main['image'].apply(lambda x: f\"../clothing-dataset/images/{x}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_w, img_h = 64, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    "\t# load the image\n",
    "\timg = load_img(filename, grayscale=True, target_size=(img_w,img_h))\n",
    "\t# img = load_img(filename, target_size=(64,64,1))\n",
    "\t\n",
    "\t# convert to array\n",
    "\timg = img_to_array(img)\n",
    "\t# reshape into a single sample with 1 channel\n",
    "\timg = img.reshape(img_w, img_h, 1)\n",
    "\t# prepare pixel data\n",
    "\timg = img.astype('float32')\n",
    "\n",
    "\t# img = 255 - img\n",
    "\t# img[img < 20] = 0\n",
    "\timg = img / 255.0\n",
    "\t# img = img.astype(int)\n",
    "\treturn img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Qasim\\anaconda3\\envs\\ai-env\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "for i,r in df_main.iterrows():\n",
    "    try:\n",
    "        im = load_image(r['img_path'])\n",
    "        dataset.append([im,r['y']])\n",
    "    except:\n",
    "        print(f\"error img -> {r['img_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Qasim\\AppData\\Local\\Temp/ipykernel_2068/1525633772.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  dataset = np.array(dataset)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3190, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to right data type as errors show up for incorrect type in model building\n",
    "X = np.stack(dataset[:,0]).astype('float32')\n",
    "y = dataset[:,1].astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reshaped_X = X.reshape(X.shape[0],-1)\n",
    "\n",
    "#oversampling\n",
    "oversample = RandomOverSampler()\n",
    "oversampled_X, oversampled_y  = oversample.fit_resample(reshaped_X , y)\n",
    "\n",
    "# reshaping X back to the first dims\n",
    "X = oversampled_X.reshape(-1,img_w,img_h,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = oversampled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4802, 64, 64, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32, # filters to learn\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        padding='valid',\n",
    "        activation='relu',\n",
    "        input_shape=(img_w,img_h,1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=32, # filters to learn\n",
    "        kernel_size=(5,5),\n",
    "        strides=(1,1),\n",
    "        padding='valid',\n",
    "        activation='relu',\n",
    "        input_shape=(img_w,img_h,1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(tf.keras.layers.experimental.preprocessing.Resizing(224,224, interpolation='nearest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor = 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'\n",
    "# feature_extractor_layer = hub.KerasLayer(feature_extractor, input_shape = (224, 224,3))\n",
    "# feature_extractor_layer.trainable = False\n",
    "# model.add(feature_extractor_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next layer we will add is a Maxpooling layer. This will reduce the \n",
    "# dimensionality of each feature, which reduces the number of parameters that \n",
    "# the model needs to learn, which shortens training time.\n",
    "model.add(\n",
    "    tf.keras.layers.MaxPooling2D(\n",
    "        pool_size=(2, 2), # Size feature will be mapped to\n",
    "        strides=(2, 2) # How the pool \"steps\" across the feature\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                802848    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 829,477\n",
      "Trainable params: 829,477\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We'll now add a dropout layer. This fights overfitting and forces the model to \n",
    "# learn multiple representations of the same data by randomly disabling neurons \n",
    "# in the learning phase.\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.30 # Randomly disable 25% of neurons\n",
    "    )\n",
    ")\n",
    "# model.add(\n",
    "#     tf.keras.layers.Dropout(\n",
    "#         rate=0.25 # Randomly disable 25% of neurons\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "# Output from previous layer is a 3D tensor. This must be flattened to a 1D \n",
    "# vector before beiung fed to the Dense Layers.\n",
    "model.add(\n",
    "    tf.keras.layers.Flatten()\n",
    ")\n",
    "\n",
    "# A dense (interconnected) layer is added for mapping the derived features \n",
    "# to the required class.\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=32, # Output shape\n",
    "        activation='relu' # Rectified Linear Unit Activation Function\n",
    "    )\n",
    ")\n",
    "\n",
    "# Final layer with 10 outputs and a softmax activation. Softmax activation \n",
    "# enables me to calculate the output based on the probabilities. \n",
    "# Each class is assigned a probability and the class with the maximum \n",
    "# probability is the modelâ€™s output for the input.\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=5, # Output shape\n",
    "        activation='softmax' # Softmax Activation Function\n",
    "    )\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy, # loss function\n",
    "    optimizer=tf.keras.optimizers.Adam(), # optimizer function\n",
    "    metrics=['accuracy'] # reporting metric\n",
    ")\n",
    "\n",
    "# Display a summary of the models structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "34/34 [==============================] - 1s 23ms/step - loss: 1.4996 - accuracy: 0.3761 - val_loss: 1.1646 - val_accuracy: 0.5850\n",
      "Epoch 2/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.9798 - accuracy: 0.6510 - val_loss: 0.8256 - val_accuracy: 0.7134\n",
      "Epoch 3/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.6736 - accuracy: 0.7679 - val_loss: 0.6374 - val_accuracy: 0.7876\n",
      "Epoch 4/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.4902 - accuracy: 0.8399 - val_loss: 0.5306 - val_accuracy: 0.8272\n",
      "Epoch 5/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.3729 - accuracy: 0.8798 - val_loss: 0.5043 - val_accuracy: 0.8411\n",
      "Epoch 6/50\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.3061 - accuracy: 0.9021 - val_loss: 0.4787 - val_accuracy: 0.8536\n",
      "Epoch 7/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.2431 - accuracy: 0.9244 - val_loss: 0.4617 - val_accuracy: 0.8640\n",
      "Epoch 8/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1737 - accuracy: 0.9470 - val_loss: 0.4376 - val_accuracy: 0.8709\n",
      "Epoch 9/50\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.1367 - accuracy: 0.9610 - val_loss: 0.4267 - val_accuracy: 0.8869\n",
      "Epoch 10/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.1166 - accuracy: 0.9655 - val_loss: 0.4653 - val_accuracy: 0.8799\n",
      "Epoch 11/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0850 - accuracy: 0.9768 - val_loss: 0.4295 - val_accuracy: 0.8897\n",
      "Epoch 12/50\n",
      "34/34 [==============================] - 1s 15ms/step - loss: 0.0563 - accuracy: 0.9866 - val_loss: 0.5254 - val_accuracy: 0.8869\n",
      "Epoch 13/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0587 - accuracy: 0.9816 - val_loss: 0.5094 - val_accuracy: 0.8862\n",
      "Epoch 14/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0422 - accuracy: 0.9899 - val_loss: 0.5238 - val_accuracy: 0.8910\n",
      "Epoch 15/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0457 - accuracy: 0.9896 - val_loss: 0.5139 - val_accuracy: 0.8959\n",
      "Epoch 16/50\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.4858 - val_accuracy: 0.8987\n",
      "Epoch 17/50\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.5341 - val_accuracy: 0.9008\n",
      "Epoch 18/50\n",
      "34/34 [==============================] - 1s 19ms/step - loss: 0.0237 - accuracy: 0.9935 - val_loss: 0.5360 - val_accuracy: 0.8924\n",
      "Epoch 19/50\n",
      "34/34 [==============================] - 1s 18ms/step - loss: 0.0248 - accuracy: 0.9935 - val_loss: 0.5467 - val_accuracy: 0.8959\n",
      "Epoch 20/50\n",
      "34/34 [==============================] - 1s 17ms/step - loss: 0.0212 - accuracy: 0.9955 - val_loss: 0.6596 - val_accuracy: 0.8910\n",
      "Epoch 21/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.6352 - val_accuracy: 0.8869\n",
      "Epoch 22/50\n",
      "34/34 [==============================] - 1s 16ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 0.5643 - val_accuracy: 0.8980\n"
     ]
    }
   ],
   "source": [
    "early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "# Train the CNN on the training data\n",
    "history = model.fit(\n",
    "    \n",
    "      # Training data : features (images) and classes.\n",
    "      x_train, y_train,\n",
    "                    \n",
    "      # number of samples to work through before updating the \n",
    "      # internal model parameters via back propagation.\n",
    "      batch_size=100, \n",
    "\n",
    "      # An epoch is an iteration over the entire training data.\n",
    "      epochs=50, \n",
    "\n",
    "      # The model will set apart his fraction of the training \n",
    "      # data, will not train on it, and will evaluate the loss\n",
    "      # and any model metrics on this data at the end of \n",
    "      # each epoch. \n",
    "      validation_split=0.3, \n",
    "      callbacks=[early_stopping],\n",
    "      verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4(hp):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input((img_w, img_h,1)))\n",
    "\n",
    "    hp_fe_11 = hp.Int('filter_exp_11', min_value=3, max_value=7, step=1)\n",
    "    hp_fe_12 = hp.Int('filter_exp_12', min_value=3, max_value=7, step=1)\n",
    "    hp_fs_11 = hp.Int('filter_size_11',  min_value=2, max_value=6, step=1)\n",
    "    hp_fs_12 = hp.Int('filter_size_12',  min_value=2, max_value=6, step=1)\n",
    "    hp_mps_1 = hp.Int('max_pool_size_1', min_value=2, max_value=6, step=1)\n",
    "\n",
    "    model.add(layers.Conv2D(2**hp_fe_11, hp_fs_11, padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(2**hp_fe_12, hp_fs_12, padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(hp_mps_1))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    hp_dense_exp_1 = hp.Int('dense_exp_1', min_value=5, max_value=9, step=1)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(units=2**hp_dense_exp_1, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(),\n",
    "                    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used Keras Tuner, to find the best hyperparameters for our models\n",
    "def model_tuner(model_builder, dir):\n",
    "\n",
    "    tuner = kt.Hyperband(model_builder,\n",
    "                        objective='val_accuracy',\n",
    "                        max_epochs=10,\n",
    "                        factor=3)\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "    tuner.search(x_train, y_train, validation_split=0.3, epochs=50, callbacks=[early_stopping])\n",
    "    best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=1)\n",
    "    print(\"\\n-- Best Model Hyper params --\\n \")\n",
    "    pp.pprint(best_hps.values)\n",
    "\n",
    "    model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    print(\"\\n-- Model Performance --\\n \")\n",
    "    \n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=50, callbacks=[early_stopping], validation_split=0.3, verbose=2)\n",
    "    score, acc = model.evaluate(x_test, y_test)\n",
    "    val_acc_per_epoch = history.history['val_accuracy']\n",
    "    best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) \n",
    "    print()\n",
    "    print('Best epoch  : %d' % (best_epoch,))\n",
    "    print(\"Best val acc: %s\" % (round(max(history.history['val_accuracy']), 4)))\n",
    "    print(\"    Test acc: %s\" % (round(acc, 4)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 10s]\n",
      "val_accuracy: 0.8882720470428467\n",
      "\n",
      "Best val_accuracy So Far: 0.9111728072166443\n",
      "Total elapsed time: 00h 02m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "-- Best Model Hyper params --\n",
      " \n",
      "{'dense_exp_1': 8,\n",
      " 'filter_exp_11': 4,\n",
      " 'filter_exp_12': 6,\n",
      " 'filter_size_11': 3,\n",
      " 'filter_size_12': 4,\n",
      " 'max_pool_size_1': 5,\n",
      " 'tuner/bracket': 0,\n",
      " 'tuner/epochs': 10,\n",
      " 'tuner/initial_epoch': 0,\n",
      " 'tuner/round': 0}\n",
      "\n",
      "-- Model Performance --\n",
      " \n",
      "Epoch 1/50\n",
      "106/106 - 1s - loss: 1.2057 - accuracy: 0.5162 - val_loss: 0.8907 - val_accuracy: 0.6801\n",
      "Epoch 2/50\n",
      "106/106 - 1s - loss: 0.6964 - accuracy: 0.7608 - val_loss: 0.5856 - val_accuracy: 0.7988\n",
      "Epoch 3/50\n",
      "106/106 - 1s - loss: 0.4647 - accuracy: 0.8450 - val_loss: 0.4833 - val_accuracy: 0.8473\n",
      "Epoch 4/50\n",
      "106/106 - 1s - loss: 0.3337 - accuracy: 0.8869 - val_loss: 0.4291 - val_accuracy: 0.8563\n",
      "Epoch 5/50\n",
      "106/106 - 1s - loss: 0.2398 - accuracy: 0.9206 - val_loss: 0.4012 - val_accuracy: 0.8765\n",
      "Epoch 6/50\n",
      "106/106 - 1s - loss: 0.1795 - accuracy: 0.9441 - val_loss: 0.3998 - val_accuracy: 0.8806\n",
      "Epoch 7/50\n",
      "106/106 - 1s - loss: 0.1462 - accuracy: 0.9572 - val_loss: 0.3519 - val_accuracy: 0.9008\n",
      "Epoch 8/50\n",
      "106/106 - 1s - loss: 0.0985 - accuracy: 0.9711 - val_loss: 0.3979 - val_accuracy: 0.8910\n",
      "Epoch 9/50\n",
      "106/106 - 1s - loss: 0.0687 - accuracy: 0.9816 - val_loss: 0.3928 - val_accuracy: 0.8966\n",
      "Epoch 10/50\n",
      "106/106 - 1s - loss: 0.0590 - accuracy: 0.9836 - val_loss: 0.3931 - val_accuracy: 0.9001\n",
      "Epoch 11/50\n",
      "106/106 - 1s - loss: 0.0462 - accuracy: 0.9881 - val_loss: 0.4024 - val_accuracy: 0.9049\n",
      "Epoch 12/50\n",
      "106/106 - 1s - loss: 0.0306 - accuracy: 0.9929 - val_loss: 0.3967 - val_accuracy: 0.9084\n",
      "Epoch 13/50\n",
      "106/106 - 1s - loss: 0.0263 - accuracy: 0.9940 - val_loss: 0.4796 - val_accuracy: 0.8966\n",
      "Epoch 14/50\n",
      "106/106 - 1s - loss: 0.0258 - accuracy: 0.9943 - val_loss: 0.4616 - val_accuracy: 0.9070\n",
      "Epoch 15/50\n",
      "106/106 - 1s - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.4654 - val_accuracy: 0.9056\n",
      "Epoch 16/50\n",
      "106/106 - 1s - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.5374 - val_accuracy: 0.8966\n",
      "Epoch 17/50\n",
      "106/106 - 1s - loss: 0.0243 - accuracy: 0.9949 - val_loss: 0.4907 - val_accuracy: 0.9042\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3255 - accuracy: 0.9130\n",
      "\n",
      "Best epoch  : 11\n",
      "Best val acc: 0.9084\n",
      "    Test acc: 0.913\n"
     ]
    }
   ],
   "source": [
    "trained_model_4 = model_tuner(model4, 'model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               2359552   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 2,377,445\n",
      "Trainable params: 2,377,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trained_model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_4.save('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shoes'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup[np.argmax(model.predict(test_img.reshape(1,64,64,1)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {value: key for key, value in dict_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[0])\n",
    "plt.title(lookup[y_test[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = x_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img1 = load_image(\"../clothing-dataset/images/0a7e5fe0-d592-40e6-b9b8-75aac9a2d685.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(\"../clothing-dataset/images/0a7e5fe0-d592-40e6-b9b8-75aac9a2d685.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = lookup[np.argmax(model.predict(test_img1.reshape(1,64,64,1)))]\n",
    "actual = lookup[y_test[0]]\n",
    "\n",
    "\"predicted: \"+  predicted, \"actual: \"+ actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 45, 1: 38, 3: 18, 4: 20, 2: 39})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 43, 2: 48, 1: 55, 4: 44, 0: 63})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1011, 4: 1011, 1: 1011, 3: 1011, 2: 1011})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image('../clothing-dataset/unknown.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x158f8ea5a00>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pants'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup[np.argmax(model.predict(img.reshape(1,64,64,1)))]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a7368ff7cdc52ddb5e44bf63afdf6ce6b912e649d48978d8b3edeb8bc60b54e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ai-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
